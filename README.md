# Using R, Python, and Apache Airflow to build Data Pipelines 

##### Introduction
This repository uses Apache Airflow with R and Python to schedule data analysis tasks. The main purpose of this repository is to document my journey learning about Data pipelines. To keep the learning engaging, I picked a real-world data set and used a series of modular scripts to analyze this data and to create visualizations. Special gratitude to [Laura Calcagni](https://lcalcagni.medium.com/running-r-scripts-in-airflow-using-airflow-bashoperators-6d827f5da5b1) for the inspiration to learn about **Apache Airflow**, and to [John Graves](https://github.com/graveja0/health-care-markets) for teaching me everything I know about R and programming. 

```

```


##### References
1. Cs√°rdi, G., Nepusz, T. and Airoldi, E.M., 2016. Statistical network analysis with igraph.
         https://sites.fas.harvard.edu/~airoldi/pub/books/BookDraft-CsardiNepuszAiroldi2016.pdf
         
         
2. Introduction to ggraph: Edges. Data Imaginist. 
         https://www.data-imaginist.com/2017/ggraph-introduction-edges/
         
         
3. John Graves. Defining Markets for Health Care Services.
         https://github.com/graveja0/health-care-markets
